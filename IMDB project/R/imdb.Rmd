---
title: "IMDB Project"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

## Setup
The goal of this project is to research which variables possibly influence the total revenue streams that a released movie generates by performing a multiple regression. For this purpose, data belonging to around 5000 movies from the Internet Movie Database (IMDB) has been used. This data has been retrieved from <a href="https://www.kaggle.com/carolzhangdc/imdb-5000-movie-dataset" target="_blank">Kaggle</a>. 

This project is of a more exploratory nature, which means that we are looking for possible connections. As such, it does not contain a strong justification for the included variables and for the analysis methods. Interpret the findings with this information in mind.

First, let's look at the available data. We start by importing the necessary libraries and by reading the csv file.

```{r}
library(dplyr)
library(tidyr)

movies <- read.csv(file="movie_metadata.csv")
```

Let's look at the columns included in this dataset:
```{r}
```


```{r}
str(movies)
```
These columns correspond to the variables that we could use for our analysis. Some of these variables will correlate with the total revenue that movies generate and others will not. In this project, potentially relevant or interesting variables will be handpicked. The variables that we choose will need a plausible connection to total revenue, as well as a sufficient degree of measurability. This means that variables of a categorical or nominal nature (e.g. 'yes/no', 'A/B/C', '0/1') will be excluded. 

The result of this handpicking is as follows:

**Dependent variable:**

* gross (total revenue stream generated by movie in USD)

**Independent variables:**

* duration (total runtime of the movie in minutes)
* budget (total budget of the movie in US dollars)
* num_critic_for_reviews (number of reviews by critics)


* director_facebook_likes (total number of movie director Facebook likes)
* cast_total_facebook_likes (total number of Facebook likes of the entire cast)

As you can see, all of these independent variables are of a numerical nature, meaning they can be measured. Also, all of them, except num_critic_for_reviews, exist before the release of the movie in question. Other variables, like imdb_score (IMDB score), num_voted_users (total number of IMDB users that voted) and movie_facebook_likes (total amount of Facebook likes for the movie) exist as a result of the movie's release. Because the total revenue is an indicator of the popularity of a movie, it is plausible that the dependent variable gross could have an effect on these variables, creating a kind of feedback loop. We want to make sure that our independent variables remain independent, which is why variables such as these have been excluded.

## Data cleaning

In this section, we "wrangle" the data into a shape that is suitable for the analysis. This section contains filtering by country, variable selection, missing value, duplicate row and outlier removal and data type correction. After every action that modifies the dataset, one of the following two lines of code will be used to display up to date information about the data:
```
summary(movies)
str(movies)
```

### Filtering by country
We want the gross and budget variables to be in US dollars. Currently, (a number of) movies that are produced outside the USA have their values in the gross and budget variables expressed in a local currency. Currency conversion rates being what they are, this can quickly lead to wildly inaccurate analysis results, which is why we filter out all movies that are produced outside the US:

```{r}
movies <- subset(movies, country == "USA")
str(movies)
```

### Variable selection
Let's modify the dataset to only contain the columns chosen for the analysis:

```{r}
movies <- movies[c("movie_title", "gross", "duration", "budget", "num_critic_for_reviews",
                   "director_facebook_likes", "cast_total_facebook_likes")]
summary(movies)
```

### Missing values
The data we have now needs to be cleaned before it can be analyzed. As can be seen above, there are 3807 rows (movies) left in the dataset, but not every row contains all the information that we want. For example, around one in four rows contain no information about the total revenue. Before we can analyze the data, any row that does not contain values for all variables will be removed:

```{r}
movies <- drop_na(movies)
str(movies)
```
As you can see, after cleaning we are left with a dataset containing 3073 rows. We can be confident that none of these rows contain any missing values.

### Duplicate removal

Duplicates are exactly matching rows that appear multiple times in the dataset. Too many duplicates will skew the analysis results. Luckily, these are easily removed:

```{r}
movies <- distinct(movies)
str(movies)
```
The number of rows has gone down from 3073 to 3006, meaning that 67 duplicate rows have been removed.

### Data type
To increase the readability of the data, we need to look at data types next. All of the columns containing numerical values actually only consist integers. This can be confirmed using the following code:

```{r}
for (col in colnames(movies)[2:7]) {
  cat(paste(col, "is integer: "))
  cat(paste(all(floor(movies[col]) == movies[col]), end="\n"))
}
```
After confirming that we are dealing with integers, the column "budget" can be recast to match the values:

```{r}
movies$budget <- as.integer(movies$budget)
str(movies)
```
You can see that the data types for all the variables have changed from float64 to int64.

### Outliers

The move industry is a competitive business and as such may be subject to something similar to the <a href="https://en.wikipedia.org/wiki/Pareto_distribution" target="_blank">Pareto distribution</a>. Some movies may see exceptionally high values in certain variables. These high values are then outliers that may skew the analysis results. Outliers must be detected and removed.

A good way to understand data is to visually represent it. The histograms below show how the variables in the dataset are distributed. The height of the bars represents the count of movies in a certain bin of the histogram.

```{r}
library(ggplot2)
library(gridExtra)

plot1 <- ggplot(movies, aes(x=gross))  + geom_histogram(bins=100, fill="blue")
plot2 <- ggplot(movies, aes(x=duration)) + geom_histogram(bins=100, fill="blue")
plot3 <- ggplot(movies, aes(x=budget)) + geom_histogram(bins=100, fill="blue")
plot4 <- ggplot(movies, aes(x=num_critic_for_reviews)) + geom_histogram(bins=100, fill="blue")
plot5 <- ggplot(movies, aes(x=director_facebook_likes)) + geom_histogram(bins=100, fill="blue")
plot6 <- ggplot(movies, aes(x=cast_total_facebook_likes)) + geom_histogram(bins=100, fill="blue")
grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, ncol = 2, top = "Variable Distributions")
```
It is immediately obvious that most of these variables are concentrated on the left side of their respective graphs. This is an indication that these variables are dealing with massive outliers that are barely visible in these histograms. The variables budget, director_facebook_likes and cast_total_facebook seem most affected by this, with the vast majority of counts on a very small section of the x-axis, and a vanishingly small amount of counts on the remainder of the x-axis. 

The risk exists that these outliers  will skew the results of the final analysis. Because of this, a new version of the dataset will be created where the most extreme outliers have been removed. We do this by calculating the z-score of every value for every variable. Values with a z-score of 3 and higher will be removed from the dataset.

```{r}
z <- as.data.frame(scale(movies[2:7]))
z$movie_title <- movies$movie_title

z_delete <- subset(z, gross >= 3 | duration >= 3 | budget >= 3 | num_critic_for_reviews >= 3 | director_facebook_likes >= 3 | cast_total_facebook_likes >= 3)
movies <- filter(movies, !movie_title %in% z_delete$movie_title)

str(movies)
```
As you can see, we are left with 2672 rows. Now let's take a look at the histograms from earlier, but with outliers removed:

```{r}
plot7 <- ggplot(movies, aes(x=gross))  + geom_histogram(bins=100, fill="blue")
plot8 <- ggplot(movies, aes(x=duration)) + geom_histogram(bins=100, fill="blue")
plot9 <- ggplot(movies, aes(x=budget)) + geom_histogram(bins=100, fill="blue")
plot10 <- ggplot(movies, aes(x=num_critic_for_reviews)) + geom_histogram(bins=100, fill="blue")
plot11 <- ggplot(movies, aes(x=director_facebook_likes)) + geom_histogram(bins=100, fill="blue")
plot12 <- ggplot(movies, aes(x=cast_total_facebook_likes)) + geom_histogram(bins=100, fill="blue")
grid.arrange(plot7, plot8, plot9, plot10, plot11, plot12, ncol = 2, top = "Variable Distributions")
```
The overall shape of the histograms is similar to before, but removing the more extreme outliers has improved the visibility and will lead to more accurate analysis results.

Our dataset is now prepared for analysis. To get an impression of what the final dataset looks like, here is a display of the 15 highest grossing movies in the dataset.

```{r}
head(movies[order(-movies$gross),], n=15L)
```

## Analysis

**Descriptive analysis**

Before running the numbers, descriptive and visual statistics will be shown. This helps the reader to get an understanding of the data. The next table displays some of the most commonly used descriptive statistics of the variables in the dataset (rounded for readability). These statistics are the mean, minimum and maximum values and the lower quartile, median and upper quartile.

```{r}
summary(movies)
```

Here are the standard deviations for each variable:
```{r}
print("Standard Deviation")
apply(movies[2:7], 2, sd)
```
**Visual analysis**

Scatter plots are a useful tool for visualizing the relationship between variables. In this case, the scatter plots display the relationship between each variable in the dataset and the dependent variable gross. The first scatter plot (top left) can be ignored.

```{r}
plot13 <- ggplot(movies, aes(x=gross, y=gross)) + geom_point(color="blue")
plot14 <- ggplot(movies, aes(x=duration, y=gross)) + geom_point(color="blue")
plot15 <- ggplot(movies, aes(x=budget, y=gross)) + geom_point(color="blue")
plot16 <- ggplot(movies, aes(x=num_critic_for_reviews, y=gross)) + geom_point(color="blue")
plot17 <- ggplot(movies, aes(x=director_facebook_likes, y=gross)) + geom_point(color="blue")
plot18 <- ggplot(movies, aes(x=cast_total_facebook_likes, y=gross)) + geom_point(color="blue")
grid.arrange(plot13, plot14, plot15, plot16, plot17, plot18, ncol = 3, top = "Variable - Gross scatter plots")
```
A number of insights can be gleaned from these scatter plots:
* Movies with a low duration tend to gross low, while movies with a long duration can go either way.
* Budget and gross seem positively correlated; movies with a higher budget generate more revenue.
* The amount of reviews by movie critics seem to not or barely correlate with total revenue.
* Extremely popular movie directors don't necessarily make high grossing movies.
* Cast popularity seems positively correlated with total revenue.

**Statistical analysis**

In this section we find out whether the data can be used to find statistically significant results, and if so, what these results are and how they fit the insights derived from the scatter plots. We make use of multiple linear regression for the statistical analysis. 

The first step is to create and fit a statistical model.

```{r}
model <- lm(gross ~ duration + budget + num_critic_for_reviews + director_facebook_likes + cast_total_facebook_likes, data=movies)
```
**Multicollinearity testing**

Multicollinearity is a term for a situation where multiple independent variables in a statistical model not only influence the dependent variable, but also each other. Too much multicollinearity will lead to unreliable analysis results.

We can test for multicollinearity by calculate the Variance Inflation Factor (VIF) for each independent variable. VIF values under 3 are ideal, VIF values over 5 indicate some multicollinearity and VIF values over 10 indicate severely problematic levels of multicollinearity.

```{r}
library(car)
vif(model)
```
The calculated VIF values are small enough that we can reliably proceed with the statistical analysis; no variables need to be removed.

Now, let's view the results of the statistical model:

```{r}
summary(model)
```
**Interpretation**

The regression results summary gives us a lot of information, not all of which is relevant. The most important results will be listed here:

- The adjusted R-squared value of 0.3705 means that 37.05% of the total variance of the dependent variable gross is explained by the independent variables included in the model. 62.95% of the total variance is not explained.

- The column "Estimate" shows the regression coefficients for each variable. As you can see, all coefficients are positive, indicating a positive relationship between the independent variable in question and the dependent variable gross.

- The column "Pr(>|t|)" shows the p-values, which indicate how statistically significant each regression coefficient is. Working with a treshold of α = 0.05, the following positive regression coefficients are statistically significant: 
    * duration
    * budget: strong positive coefficient
    * num_critic_for_reviews
    * director_facebook_likes

**Export**

The analysis is concluded. We can now export the final dataset as a csv file to be used with other tools, such as database or visualization software.

```{r}
write.csv2(movies, "movies_output.csv", row.names=FALSE)
```
